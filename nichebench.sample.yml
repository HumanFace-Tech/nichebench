# NicheBench Configuration
# This file controls model settings, evaluation parameters, and global behavior

# Model Under Test (MUT) configuration
mut:
  provider: "groq"
  model: "openai/gpt-oss-120b"          # GPT-5 Mini (released August 7, 2025)
  parameters:
    temperature: 0
    max_tokens: 32768
    top_p: 1.0
    # Note: reasoning parameters only work with o1 models
    # reasoning_effort: "medium"  # "low", "medium", "high", or null to disable
    # reasoning_format: "hidden"  # "hidden" or "visible" - hidden is ideal for MUT

# Judge model configuration
judge:
  provider: "openai"
  model: "gpt-5"
  parameters:
    temperature: 1.0
    max_tokens: 32768
    top_p: 1.0
    # Judge typically doesn't need reasoning params, but available if needed
    # reasoning_effort: "low"
    # reasoning_format: "visible"

# Global evaluation settings
evaluation:
  save_full_prompts: true       # Include full input prompts in results
  save_raw_outputs: true        # Include raw model outputs
  parallel_workers: 1           # Number of parallel evaluation workers

# Network and reliability settings
network:
  timeout: 600                  # Request timeout in seconds (increased for large token generation)
  retry_attempts: 5             # Number of retry attempts for failed requests (default: 5)
  retry_delay: 3.0             # Base delay between retries in seconds (default: 3.0)
                               # Uses exponential backoff: delay * (2^attempt) with ±20% jitter
                               # Example: 3s → 6s → 12s → 24s → 48s (with random variation)
                               # Retryable errors: timeout, rate limit, server errors, network errors

# Results and reporting
results:
  auto_report: true             # Show rich report after each run
  save_format: "jsonl"          # Format: jsonl, json, csv
  timestamp_format: "%Y%m%d_%H%M%S"

# Framework-specific recommendations (commented examples)
# frameworks:
#   drupal:
#     recommended_mut_models:
#       - {provider: "groq", model: "llama3-70b-8192", temp: 0.0}
#       - {provider: "openai", model: "o1-mini", reasoning_effort: "high"}
#       - {provider: "anthropic", model: "claude-3-5-sonnet-20241022", temp: 0.0}
#
#   wordpress:
#     recommended_mut_models:
#       - {provider: "openai", model: "gpt-4o", temp: 0.1}

# Configuration profiles for different evaluation scenarios
profiles:
  # Fast evaluation with cost-effective models
  groq:
    mut:
      provider: "groq"
      model: "llama-3.1-8b-instant"
      parameters:
        temperature: 0.1
        max_tokens: 2048
    judge:
      provider: "groq"
      model: "meta-llama/llama-4-maverick-17b-128e-instruct"

  # Claude-based evaluation
  anthropic:
    mut:
      provider: "anthropic"
      model: "claude-3-5-sonnet-20241022"
      parameters:
        temperature: 0.0
        max_tokens: 4096
    judge:
      provider: "anthropic"
      model: "claude-3-haiku-20240307"
#
#   budget:
#     mut: {provider: "together", model: "meta-llama/Llama-3-8b-chat-hf", temp: 0.0}
#     judge: {provider: "groq", model: "llama3-70b-8192", temp: 0.5}
